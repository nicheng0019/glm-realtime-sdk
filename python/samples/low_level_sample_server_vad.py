# Copyright (c) ZhiPu Corporation.
# Licensed under the MIT license.

import argparse
import asyncio
import base64
import os
import signal
from typing import Optional

import pyaudio
from dotenv import load_dotenv
from message_handler import create_message_handler

from rtclient import RTLowLevelClient
from rtclient.models import (
    InputAudioBufferAppendMessage,
    ServerVAD,
    SessionUpdateMessage,
    SessionUpdateParams,
)

shutdown_event: Optional[asyncio.Event] = None
session_ready_event: Optional[asyncio.Event] = None  # ä¼šè¯å‡†å¤‡å°±ç»ªäº‹ä»¶

# å»¶è¿Ÿç»Ÿè®¡
class LatencyStats:
    def __init__(self):
        self.mic_to_send_latencies = []
        self.text_to_audio_latencies = []
        self.last_mic_latency = 0.0
        self.last_text_latency = 0.0

    def add_mic_to_send(self, latency_ms: float):
        self.mic_to_send_latencies.append(latency_ms)
        self.last_mic_latency = latency_ms

    def add_text_to_audio(self, latency_ms: float):
        self.text_to_audio_latencies.append(latency_ms)
        self.last_text_latency = latency_ms

    def get_current_stats(self) -> str:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯çš„å­—ç¬¦ä¸²"""
        stats = []
        if self.mic_to_send_latencies:
            avg_mic = sum(self.mic_to_send_latencies) / len(self.mic_to_send_latencies)
            stats.append(f"éº¦å…‹é£â†’å‘é€: å½“å‰={self.last_mic_latency:.1f}ms å¹³å‡={avg_mic:.1f}ms")
        if self.text_to_audio_latencies:
            avg_text = sum(self.text_to_audio_latencies) / len(self.text_to_audio_latencies)
            stats.append(f"æ–‡å­—â†’éŸ³é¢‘: å½“å‰={self.last_text_latency:.1f}ms å¹³å‡={avg_text:.1f}ms")
        return " | ".join(stats) if stats else "æš‚æ— æ•°æ®"

    def print_stats(self):
        print("\n" + "=" * 70)
        if self.mic_to_send_latencies:
            avg_mic = sum(self.mic_to_send_latencies) / len(self.mic_to_send_latencies)
            min_mic = min(self.mic_to_send_latencies)
            max_mic = max(self.mic_to_send_latencies)
            print(f"ğŸ“Š éº¦å…‹é£åˆ°å‘é€å»¶è¿Ÿç»Ÿè®¡ (å…± {len(self.mic_to_send_latencies)} ä¸ªæ ·æœ¬):")
            print(f"   å¹³å‡: {avg_mic:.2f}ms | æœ€å°: {min_mic:.2f}ms | æœ€å¤§: {max_mic:.2f}ms")
        else:
            print("ğŸ“Š éº¦å…‹é£åˆ°å‘é€å»¶è¿Ÿç»Ÿè®¡: æš‚æ— æ•°æ®")

        if self.text_to_audio_latencies:
            avg_text = sum(self.text_to_audio_latencies) / len(self.text_to_audio_latencies)
            min_text = min(self.text_to_audio_latencies)
            max_text = max(self.text_to_audio_latencies)
            print(f"ğŸ“Š æ–‡å­—å“åº”åˆ°éŸ³é¢‘ç”Ÿæˆå»¶è¿Ÿç»Ÿè®¡ (å…± {len(self.text_to_audio_latencies)} ä¸ªæ ·æœ¬):")
            print(f"   å¹³å‡: {avg_text:.2f}ms | æœ€å°: {min_text:.2f}ms | æœ€å¤§: {max_text:.2f}ms")
        else:
            print("ğŸ“Š æ–‡å­—å“åº”åˆ°éŸ³é¢‘ç”Ÿæˆå»¶è¿Ÿç»Ÿè®¡: æš‚æ— æ•°æ®")
        print("=" * 70 + "\n")

latency_stats = LatencyStats()


def handle_shutdown(sig=None, frame=None):
    """å¤„ç†å…³é—­ä¿¡å·"""
    if shutdown_event:
        print("\næ­£åœ¨å…³é—­ç¨‹åº...")
        latency_stats.print_stats()
        shutdown_event.set()


async def send_audio_from_mic(client: RTLowLevelClient, enable_mic_playback: bool = False):
    """
    ä»éº¦å…‹é£å®æ—¶å½•éŸ³å¹¶å‘é€éŸ³é¢‘ï¼š
    DefaultServerVADCfg
    var DefaultVadConfig = VadConfig{
        PositiveSpeechThreshold: 0.85,
        NegativeSpeechThreshold: 0.35,
        RedemptionFrames:        8, // 8x96ms = 768ms
        MinSpeechFrames:         3, // 3x96ms = 288ms
        PreSpeechPadFrames:      1,
        FrameSamples:            1536, // 96ms
        VadInterval:             32 * time.Millisecond,
    }

    Args:
        client: WebSocketå®¢æˆ·ç«¯
        enable_mic_playback: æ˜¯å¦å¯ç”¨éº¦å…‹é£éŸ³é¢‘å›æ”¾ï¼ˆç›‘å¬è‡ªå·±çš„å£°éŸ³ï¼‰
    """
    # ç­‰å¾…ä¼šè¯å‡†å¤‡å°±ç»ª
    if session_ready_event:
        print("â³ ç­‰å¾…ä¼šè¯é…ç½®å®Œæˆ...")
        await session_ready_event.wait()
        print("âœ… ä¼šè¯å·²å°±ç»ªï¼Œå¼€å§‹å½•éŸ³")

    # éŸ³é¢‘å‚æ•° (PCM16 æ ¼å¼)
    channels = 1  # å•å£°é“
    sample_width = 2  # 16ä½ (PCM16)
    frame_rate = 16000  # 16kHzé‡‡æ ·ç‡
    packet_ms = 100  # æ¯åŒ…æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰- å¯è°ƒæ•´ä¸º 50-100ms
    packet_samples = int(frame_rate * packet_ms / 1000)  # æ¯åŒ…é‡‡æ ·ç‚¹æ•°

    print(f"éŸ³é¢‘ä¿¡æ¯: æ ¼å¼=PCM16, é‡‡æ ·ç‡={frame_rate}Hz, å£°é“æ•°={channels}, ä½æ·±={sample_width*8}ä½")
    print(f"æ•°æ®åŒ…å¤§å°: {packet_ms}ms")
    print("å¼€å§‹ä»éº¦å…‹é£å½•éŸ³ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
    print("æç¤º: è¯´è¯ååœé¡¿ 0.5 ç§’ä»¥è§¦å‘å“åº”")
    if enable_mic_playback:
        print("âš ï¸  éº¦å…‹é£å›æ”¾å·²å¯ç”¨ - ä½ å°†å¬åˆ°è‡ªå·±çš„å£°éŸ³ï¼ˆå¯èƒ½äº§ç”Ÿå›å£°ï¼‰")

    p = pyaudio.PyAudio()
    stream = None
    playback_stream = None

    try:
        # æ‰“å¼€éº¦å…‹é£æµï¼ˆè¾“å…¥ï¼‰
        stream = p.open(
            format=p.get_format_from_width(sample_width),
            channels=channels,
            rate=frame_rate,
            input=True,
            frames_per_buffer=packet_samples,
        )

        # å¦‚æœå¯ç”¨å›æ”¾ï¼Œæ‰“å¼€æ’­æ”¾æµï¼ˆè¾“å‡ºï¼‰
        if enable_mic_playback:
            playback_stream = p.open(
                format=p.get_format_from_width(sample_width),
                channels=channels,
                rate=frame_rate,
                output=True,
                frames_per_buffer=packet_samples,
            )

        # æŒç»­å½•éŸ³å¹¶å‘é€
        while not shutdown_event.is_set():
            try:
                # è®°å½•éº¦å…‹é£è¯»å–å¼€å§‹æ—¶é—´
                mic_start_time = asyncio.get_event_loop().time() * 1000

                # ä»éº¦å…‹é£è¯»å–éŸ³é¢‘æ•°æ®
                packet_data = stream.read(packet_samples, exception_on_overflow=False)

                # å¦‚æœå¯ç”¨å›æ”¾ï¼Œç›´æ¥æ’­æ”¾éº¦å…‹é£éŸ³é¢‘
                if enable_mic_playback and playback_stream:
                    playback_stream.write(packet_data)

                # ç›´æ¥ä½¿ç”¨ PCM16 æ ¼å¼ï¼ˆä¸éœ€è¦ WAV å°è£…ï¼‰
                # packet_data å·²ç»æ˜¯ PCM16 æ ¼å¼çš„åŸå§‹éŸ³é¢‘æ•°æ®
                base64_data = base64.b64encode(packet_data).decode("utf-8")
                message = InputAudioBufferAppendMessage(
                    audio=base64_data, client_timestamp=int(asyncio.get_event_loop().time() * 1000)
                )

                await client.send(message)

                # è®¡ç®—å¹¶è®°å½•å»¶è¿Ÿ
                send_end_time = asyncio.get_event_loop().time() * 1000
                latency = send_end_time - mic_start_time
                latency_stats.add_mic_to_send(latency)

                # æ¯100ä¸ªæ•°æ®åŒ…æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ï¼ˆçº¦10ç§’ï¼‰
                if len(latency_stats.mic_to_send_latencies) % 100 == 0:
                    print(f"\nâ±ï¸  å»¶è¿Ÿç»Ÿè®¡: {latency_stats.get_current_stats()}\n")

            except Exception as e:
                if shutdown_event.is_set():
                    break
                print(f"å‘é€å¤±è´¥: {e}")
                break

    except Exception as e:
        print(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if stream:
            stream.stop_stream()
            stream.close()
        if playback_stream:
            playback_stream.stop_stream()
            playback_stream.close()
        p.terminate()
        print("éº¦å…‹é£å·²å…³é—­")


def get_env_var(var_name: str) -> str:
    value = os.environ.get(var_name)
    if not value:
        raise OSError(f"ç¯å¢ƒå˜é‡ '{var_name}' æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
    return value


async def with_zhipu(enable_mic_playback: bool = False):
    global shutdown_event, session_ready_event
    shutdown_event = asyncio.Event()
    session_ready_event = asyncio.Event()

    for sig in (signal.SIGINT, signal.SIGTERM):
        signal.signal(sig, handle_shutdown)

    api_key = get_env_var("ZHIPU_API_KEY")
    try:
        async with RTLowLevelClient(
            url="wss://open.bigmodel.cn/api/paas/v4/realtime", headers={"Authorization": f"Bearer {api_key}"}
        ) as client:
            if shutdown_event.is_set():
                return

            # åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨ï¼ˆåœ¨å‘é€ session æ¶ˆæ¯ä¹‹å‰ï¼‰
            message_handler = await create_message_handler(
                client,
                shutdown_event,
                enable_audio_playback=True,
                latency_stats=latency_stats,
                session_ready_event=session_ready_event
            )

            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡ï¼ˆå…ˆå¯åŠ¨æ¥æ”¶ï¼Œæ‰èƒ½æ”¶åˆ° session.updatedï¼‰
            receive_task = asyncio.create_task(message_handler.receive_messages())

            # å‘é€ä¼šè¯é…ç½®æ¶ˆæ¯
            session_message = SessionUpdateMessage(
                session=SessionUpdateParams(
                    model="glm-realtime-flash",
                    input_audio_format="pcm",
                    output_audio_format="pcm",
                    modalities={"audio", "text"},
                    turn_detection=ServerVAD(
                        threshold=0.6,              # è¯­éŸ³æ£€æµ‹é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
                        prefix_padding_ms=200,      # è¯­éŸ³å‰å¡«å…… 300ms
                        silence_duration_ms=300     # æ£€æµ‹åˆ° 500ms é™éŸ³åè®¤ä¸ºè¯´è¯ç»“æŸ
                    ),
                    input_audio_noise_reduction={
                            "type": "near_field"
                        },
                    temperature=0.01,
                    max_response_output_tokens=512,
                    voice="female-tianmei",
                    beta_fields={"chat_mode": "audio", "tts_source": "e2e", "auto_search": True,"greeting_config": {
                            "enable": True,
                            "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ™ºï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}},
                    tools=[],
                )
            )
            print("ğŸ“¤ å‘é€ä¼šè¯é…ç½®...")
            await client.send(session_message)

            if shutdown_event.is_set():
                return

            # åˆ›å»ºå‘é€ä»»åŠ¡ï¼ˆä¼šç­‰å¾… session.updated äº‹ä»¶ï¼‰
            send_task = asyncio.create_task(send_audio_from_mic(client, enable_mic_playback=enable_mic_playback))

            try:
                await asyncio.gather(send_task, receive_task)
            except Exception as e:
                print(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")
                for task in [send_task, receive_task]:
                    if not task.done():
                        task.cancel()
                        try:
                            await task
                        except asyncio.CancelledError:
                            pass
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        if shutdown_event.is_set():
            print("ç¨‹åºå·²å®Œæˆé€€å‡º")
        latency_stats.print_stats()


if __name__ == "__main__":
    load_dotenv()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="å®æ—¶è¯­éŸ³å¯¹è¯ç¨‹åº")
    parser.add_argument(
        "--mic-playback",
        action="store_true",
        help="å¯ç”¨éº¦å…‹é£éŸ³é¢‘å›æ”¾ï¼ˆç›‘å¬è‡ªå·±çš„å£°éŸ³ï¼Œå¯èƒ½äº§ç”Ÿå›å£°ï¼‰"
    )
    args = parser.parse_args()

    print("å®æ—¶è¯­éŸ³å¯¹è¯ç¨‹åº")
    print("ä½¿ç”¨éº¦å…‹é£è¿›è¡Œå®æ—¶è¯­éŸ³è¾“å…¥")
    print("æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    if args.mic_playback:
        print("âš ï¸  éº¦å…‹é£å›æ”¾å·²å¯ç”¨")
    print("-" * 50)

    try:
        asyncio.run(with_zhipu(enable_mic_playback=args.mic_playback))
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        latency_stats.print_stats()
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        latency_stats.print_stats()
    finally:
        print("ç¨‹åºå·²é€€å‡º")

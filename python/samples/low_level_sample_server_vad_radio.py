# Copyright (c) ZhiPu Corporation.
# Licensed under the MIT license.

import argparse
import asyncio
import base64
import os
import signal
import wave
from typing import Optional

import pyaudio
from dotenv import load_dotenv
from message_handler import create_message_handler

from rtclient import RTLowLevelClient
from rtclient.models import (
    InputAudioBufferAppendMessage,
    ServerVAD,
    SessionUpdateMessage,
    SessionUpdateParams,
)

shutdown_event: Optional[asyncio.Event] = None
session_ready_event: Optional[asyncio.Event] = None  # ä¼šè¯å‡†å¤‡å°±ç»ªäº‹ä»¶

# å»¶è¿Ÿç»Ÿè®¡
class LatencyStats:
    def __init__(self):
        self.mic_to_send_latencies = []
        self.text_to_audio_latencies = []
        self.last_mic_latency = 0.0
        self.last_text_latency = 0.0

    def add_mic_to_send(self, latency_ms: float):
        self.mic_to_send_latencies.append(latency_ms)
        self.last_mic_latency = latency_ms

    def add_text_to_audio(self, latency_ms: float):
        self.text_to_audio_latencies.append(latency_ms)
        self.last_text_latency = latency_ms

    def get_current_stats(self) -> str:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯çš„å­—ç¬¦ä¸²"""
        stats = []
        if self.mic_to_send_latencies:
            avg_mic = sum(self.mic_to_send_latencies) / len(self.mic_to_send_latencies)
            stats.append(f"éº¦å…‹é£â†’å‘é€: å½“å‰={self.last_mic_latency:.1f}ms å¹³å‡={avg_mic:.1f}ms")
        if self.text_to_audio_latencies:
            avg_text = sum(self.text_to_audio_latencies) / len(self.text_to_audio_latencies)
            stats.append(f"æ–‡å­—â†’éŸ³é¢‘: å½“å‰={self.last_text_latency:.1f}ms å¹³å‡={avg_text:.1f}ms")
        return " | ".join(stats) if stats else "æš‚æ— æ•°æ®"

    def print_stats(self):
        print("\n" + "=" * 70)
        if self.mic_to_send_latencies:
            avg_mic = sum(self.mic_to_send_latencies) / len(self.mic_to_send_latencies)
            min_mic = min(self.mic_to_send_latencies)
            max_mic = max(self.mic_to_send_latencies)
            print(f"ğŸ“Š éº¦å…‹é£åˆ°å‘é€å»¶è¿Ÿç»Ÿè®¡ (å…± {len(self.mic_to_send_latencies)} ä¸ªæ ·æœ¬):")
            print(f"   å¹³å‡: {avg_mic:.2f}ms | æœ€å°: {min_mic:.2f}ms | æœ€å¤§: {max_mic:.2f}ms")
        else:
            print("ğŸ“Š éº¦å…‹é£åˆ°å‘é€å»¶è¿Ÿç»Ÿè®¡: æš‚æ— æ•°æ®")

        if self.text_to_audio_latencies:
            avg_text = sum(self.text_to_audio_latencies) / len(self.text_to_audio_latencies)
            min_text = min(self.text_to_audio_latencies)
            max_text = max(self.text_to_audio_latencies)
            print(f"ğŸ“Š æ–‡å­—å“åº”åˆ°éŸ³é¢‘ç”Ÿæˆå»¶è¿Ÿç»Ÿè®¡ (å…± {len(self.text_to_audio_latencies)} ä¸ªæ ·æœ¬):")
            print(f"   å¹³å‡: {avg_text:.2f}ms | æœ€å°: {min_text:.2f}ms | æœ€å¤§: {max_text:.2f}ms")
        else:
            print("ğŸ“Š æ–‡å­—å“åº”åˆ°éŸ³é¢‘ç”Ÿæˆå»¶è¿Ÿç»Ÿè®¡: æš‚æ— æ•°æ®")
        print("=" * 70 + "\n")

latency_stats = LatencyStats()


def handle_shutdown(sig=None, frame=None):
    """å¤„ç†å…³é—­ä¿¡å·"""
    if shutdown_event:
        print("\næ­£åœ¨å…³é—­ç¨‹åº...")
        latency_stats.print_stats()
        shutdown_event.set()


async def send_audio_from_file(client: RTLowLevelClient, audio_file_path: str, enable_playback: bool = False):
    """
    ä»WAVæ–‡ä»¶æµå¼è¯»å–å¹¶å‘é€éŸ³é¢‘ï¼š
    DefaultServerVADCfg
    var DefaultVadConfig = VadConfig{
        PositiveSpeechThreshold: 0.85,
        NegativeSpeechThreshold: 0.35,
        RedemptionFrames:        8, // 8x96ms = 768ms
        MinSpeechFrames:         3, // 3x96ms = 288ms
        PreSpeechPadFrames:      1,
        FrameSamples:            1536, // 96ms
        VadInterval:             32 * time.Millisecond,
    }

    Args:
        client: WebSocketå®¢æˆ·ç«¯
        audio_file_path: WAVéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        enable_playback: æ˜¯å¦å¯ç”¨éŸ³é¢‘å›æ”¾
    """
    # ç­‰å¾…ä¼šè¯å‡†å¤‡å°±ç»ª
    if session_ready_event:
        print("â³ ç­‰å¾…ä¼šè¯é…ç½®å®Œæˆ...")
        await session_ready_event.wait()
        print("âœ… ä¼šè¯å·²å°±ç»ªï¼Œå¼€å§‹å‘é€éŸ³é¢‘æ–‡ä»¶")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_file_path):
        print(f"âŒ é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
        return

    p = pyaudio.PyAudio()
    playback_stream = None

    try:
        # æ‰“å¼€WAVæ–‡ä»¶
        with wave.open(audio_file_path, 'rb') as wf:
            # è·å–éŸ³é¢‘å‚æ•°
            channels = wf.getnchannels()
            sample_width = wf.getsampwidth()
            frame_rate = wf.getframerate()

            # ç›®æ ‡å‚æ•° (PCM16 æ ¼å¼)
            target_channels = 1  # å•å£°é“
            target_sample_width = 2  # 16ä½ (PCM16)
            target_frame_rate = 16000  # 16kHzé‡‡æ ·ç‡
            packet_ms = 100  # æ¯åŒ…æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
            packet_samples = int(target_frame_rate * packet_ms / 1000)  # æ¯åŒ…é‡‡æ ·ç‚¹æ•°

            print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {audio_file_path}")
            print(f"åŸå§‹éŸ³é¢‘ä¿¡æ¯: æ ¼å¼=PCM{sample_width*8}, é‡‡æ ·ç‡={frame_rate}Hz, å£°é“æ•°={channels}")
            print(f"ç›®æ ‡éŸ³é¢‘ä¿¡æ¯: æ ¼å¼=PCM16, é‡‡æ ·ç‡={target_frame_rate}Hz, å£°é“æ•°={target_channels}, ä½æ·±={target_sample_width*8}ä½")
            print(f"æ•°æ®åŒ…å¤§å°: {packet_ms}ms")
            print("å¼€å§‹æµå¼å‘é€éŸ³é¢‘æ–‡ä»¶ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")

            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼æ˜¯å¦åŒ¹é…
            if channels != target_channels or sample_width != target_sample_width or frame_rate != target_frame_rate:
                print(f"âš ï¸  è­¦å‘Š: éŸ³é¢‘æ ¼å¼ä¸åŒ¹é…ï¼Œéœ€è¦è½¬æ¢")
                print(f"   æœŸæœ›: {target_channels}å£°é“, {target_sample_width*8}ä½, {target_frame_rate}Hz")
                print(f"   å®é™…: {channels}å£°é“, {sample_width*8}ä½, {frame_rate}Hz")
                # è¿™é‡Œå¯ä»¥æ·»åŠ éŸ³é¢‘æ ¼å¼è½¬æ¢é€»è¾‘ï¼Œæˆ–è€…è¦æ±‚ç”¨æˆ·æä¾›æ­£ç¡®æ ¼å¼çš„æ–‡ä»¶
                # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾æ–‡ä»¶æ ¼å¼æ­£ç¡®

            # å¦‚æœå¯ç”¨å›æ”¾ï¼Œæ‰“å¼€æ’­æ”¾æµï¼ˆè¾“å‡ºï¼‰
            if enable_playback:
                playback_stream = p.open(
                    format=p.get_format_from_width(sample_width),
                    channels=channels,
                    rate=frame_rate,
                    output=True,
                    frames_per_buffer=packet_samples,
                )
                print("âš ï¸  éŸ³é¢‘å›æ”¾å·²å¯ç”¨")

            # æŒç»­è¯»å–å¹¶å‘é€
            while not shutdown_event.is_set():
                try:
                    # è®°å½•è¯»å–å¼€å§‹æ—¶é—´
                    read_start_time = asyncio.get_event_loop().time() * 1000

                    # ä»æ–‡ä»¶è¯»å–éŸ³é¢‘æ•°æ®
                    packet_data = wf.readframes(packet_samples)

                    # å¦‚æœè¯»å–åˆ°æ–‡ä»¶æœ«å°¾ï¼Œé€€å‡ºå¾ªç¯
                    if len(packet_data) == 0:
                        print("\nâœ… éŸ³é¢‘æ–‡ä»¶å‘é€å®Œæˆ")
                        break

                    # å¦‚æœå¯ç”¨å›æ”¾ï¼Œæ’­æ”¾éŸ³é¢‘
                    if enable_playback and playback_stream:
                        playback_stream.write(packet_data)

                    # ç›´æ¥ä½¿ç”¨ PCM16 æ ¼å¼ï¼ˆä¸éœ€è¦ WAV å°è£…ï¼‰
                    # packet_data å·²ç»æ˜¯ PCM16 æ ¼å¼çš„åŸå§‹éŸ³é¢‘æ•°æ®
                    base64_data = base64.b64encode(packet_data).decode("utf-8")
                    message = InputAudioBufferAppendMessage(
                        audio=base64_data, client_timestamp=int(asyncio.get_event_loop().time() * 1000)
                    )

                    await client.send(message)

                    # è®¡ç®—å¹¶è®°å½•å»¶è¿Ÿ
                    send_end_time = asyncio.get_event_loop().time() * 1000
                    latency = send_end_time - read_start_time
                    latency_stats.add_mic_to_send(latency)

                    # æ¯100ä¸ªæ•°æ®åŒ…æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ï¼ˆçº¦10ç§’ï¼‰
                    if len(latency_stats.mic_to_send_latencies) % 100 == 0:
                        print(f"\nâ±ï¸  å»¶è¿Ÿç»Ÿè®¡: {latency_stats.get_current_stats()}\n")

                    # æ¨¡æ‹Ÿå®æ—¶æ’­æ”¾é€Ÿåº¦ï¼ˆæŒ‰ç…§éŸ³é¢‘æ—¶é•¿ç­‰å¾…ï¼‰
                    await asyncio.sleep(packet_ms / 1000.0)

                except Exception as e:
                    if shutdown_event.is_set():
                        break
                    print(f"å‘é€å¤±è´¥: {e}")
                    break

    except Exception as e:
        print(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if playback_stream:
            playback_stream.stop_stream()
            playback_stream.close()
        p.terminate()
        print("éŸ³é¢‘æ–‡ä»¶å‘é€å·²å…³é—­")


def get_env_var(var_name: str) -> str:
    value = os.environ.get(var_name)
    if not value:
        raise OSError(f"ç¯å¢ƒå˜é‡ '{var_name}' æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
    return value


async def with_zhipu(audio_file_path: str, enable_playback: bool = False):
    global shutdown_event, session_ready_event
    shutdown_event = asyncio.Event()
    session_ready_event = asyncio.Event()

    for sig in (signal.SIGINT, signal.SIGTERM):
        signal.signal(sig, handle_shutdown)

    api_key = get_env_var("ZHIPU_API_KEY")
    try:
        async with RTLowLevelClient(
            url="wss://open.bigmodel.cn/api/paas/v4/realtime", headers={"Authorization": f"Bearer {api_key}"}
        ) as client:
            if shutdown_event.is_set():
                return

            # åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨ï¼ˆåœ¨å‘é€ session æ¶ˆæ¯ä¹‹å‰ï¼‰
            message_handler = await create_message_handler(
                client,
                shutdown_event,
                enable_audio_playback=True,
                latency_stats=latency_stats,
                session_ready_event=session_ready_event
            )

            # å¯åŠ¨æ¥æ”¶ä»»åŠ¡ï¼ˆå…ˆå¯åŠ¨æ¥æ”¶ï¼Œæ‰èƒ½æ”¶åˆ° session.updatedï¼‰
            receive_task = asyncio.create_task(message_handler.receive_messages())

            # å‘é€ä¼šè¯é…ç½®æ¶ˆæ¯
            session_message = SessionUpdateMessage(
                session=SessionUpdateParams(
                    model="glm-realtime-flash",
                    input_audio_format="pcm",
                    output_audio_format="pcm",
                    modalities={"audio", "text"},
                    turn_detection=ServerVAD(
                        threshold=0.6,              # è¯­éŸ³æ£€æµ‹é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
                        prefix_padding_ms=200,      # è¯­éŸ³å‰å¡«å…… 300ms
                        silence_duration_ms=300     # æ£€æµ‹åˆ° 500ms é™éŸ³åè®¤ä¸ºè¯´è¯ç»“æŸ
                    ),
                    input_audio_noise_reduction={
                            "type": "near_field"
                        },
                    temperature=0.01,
                    max_response_output_tokens=512,
                    voice="female-tianmei",
                    beta_fields={"chat_mode": "audio", "tts_source": "e2e", "auto_search": True,"greeting_config": {
                            "enable": True,
                            "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ™ºï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}},
                    tools=[],
                )
            )
            print("ğŸ“¤ å‘é€ä¼šè¯é…ç½®...")
            await client.send(session_message)

            if shutdown_event.is_set():
                return

            # åˆ›å»ºå‘é€ä»»åŠ¡ï¼ˆä¼šç­‰å¾… session.updated äº‹ä»¶ï¼‰
            send_task = asyncio.create_task(send_audio_from_file(client, audio_file_path, enable_playback=enable_playback))

            try:
                await asyncio.gather(send_task, receive_task)
            except Exception as e:
                print(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")
                for task in [send_task, receive_task]:
                    if not task.done():
                        task.cancel()
                        try:
                            await task
                        except asyncio.CancelledError:
                            pass
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        if shutdown_event.is_set():
            print("ç¨‹åºå·²å®Œæˆé€€å‡º")
        latency_stats.print_stats()


if __name__ == "__main__":
    load_dotenv()

    # é»˜è®¤éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    default_audio_file = r".\samples\input\give_me_a_joke.wav"

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="å®æ—¶è¯­éŸ³å¯¹è¯ç¨‹åºï¼ˆä»æ–‡ä»¶è¾“å…¥ï¼‰")
    parser.add_argument(
        "--audio-file",
        type=str,
        default=default_audio_file,
        help=f"éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {default_audio_file})"
    )
    parser.add_argument(
        "--playback",
        action="store_true",
        help="å¯ç”¨éŸ³é¢‘å›æ”¾ï¼ˆæ’­æ”¾å‘é€çš„éŸ³é¢‘ï¼‰"
    )
    args = parser.parse_args()

    print("å®æ—¶è¯­éŸ³å¯¹è¯ç¨‹åºï¼ˆæ–‡ä»¶è¾“å…¥æ¨¡å¼ï¼‰")
    print(f"éŸ³é¢‘æ–‡ä»¶: {args.audio_file}")
    print("æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    if args.playback:
        print("âš ï¸  éŸ³é¢‘å›æ”¾å·²å¯ç”¨")
    print("-" * 50)

    try:
        asyncio.run(with_zhipu(audio_file_path=args.audio_file, enable_playback=args.playback))
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        latency_stats.print_stats()
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        latency_stats.print_stats()
    finally:
        print("ç¨‹åºå·²é€€å‡º")
